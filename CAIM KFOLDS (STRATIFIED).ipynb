{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5b9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737cfb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_caim(xj, yj, D):\n",
    "    sp = [0] + [xj.searchsorted(point) for point in D[1:-1]] + [len(xj)]\n",
    "    n = len(sp) - 1\n",
    "    isum = 0\n",
    "    for j in range(n):\n",
    "        init = sp[j]\n",
    "        fin = sp[j + 1]\n",
    "        segment = yj[init:fin]  \n",
    "        Mr = segment.shape[0]\n",
    "        if Mr == 0:\n",
    "            continue\n",
    "        _, counts = np.unique(segment, return_counts=True)\n",
    "        maxr = counts.max()\n",
    "        isum += (maxr / Mr) * maxr\n",
    "    return isum / n if n > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8a82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caim(df, verbose=False):\n",
    "    json = {} #aquí se van a guardar las particiones\n",
    "    label_column = df.columns[-1]  # Selecciona automáticamente la última columna como etiquetas\n",
    "    y = df[label_column]\n",
    "    clases = y.unique()\n",
    "    min_splits = clases.shape[0]\n",
    "    if verbose:\n",
    "        print(f\"hay un máximo de {min_splits} cortes\")\n",
    "    \n",
    "    # Procesa todas las columnas excepto la última\n",
    "    for column in df.columns[:-1]:\n",
    "        xj_sorted = df[column].sort_values() #ordena los valores de la columna\n",
    "        yj_sorted = y.reindex(xj_sorted.index)  # Reordena las etiquetas de acuerdo con el orden de xj_sorted\n",
    "        \n",
    "        division_points = xj_sorted.unique()[1:-1] #todos los posibles puntos de corte\n",
    "        gc = -1 #global caim inicia -1 para asegurar que el primer caim lo reemplace\n",
    "        D = [xj_sorted.iloc[0], xj_sorted.iloc[-1]] #primer corte: [min,max]\n",
    "        bc = 0 #best caim, el mejor caim inicia en 0\n",
    "        mejor_D = D.copy() # el mejor D es el inicial, luego será reemplazado\n",
    "        k = 1 #valor que servirá de criterio de paro\n",
    "        \n",
    "        while k <= min_splits and (gc < bc or len(division_points) > 0):\n",
    "            #es poco probable que los primeros valores sean útiles para el corte\n",
    "            #por eso se hace una permutación para hallar el mejor caim antes\n",
    "            midpoints = np.random.permutation(division_points).tolist() \n",
    "            best_caim = 0\n",
    "            k += 1\n",
    "            if verbose:\n",
    "                print(f\"ahora k vale {k}\")\n",
    "            while midpoints:\n",
    "                sp = midpoints.pop() #sacamos el valor para hacer corte\n",
    "                D_temp = D.copy()\n",
    "                D_temp.append(sp) #cortamos el principal scheeme\n",
    "                D_temp.sort()\n",
    "                caim_value = calculate_caim(xj_sorted, yj_sorted, D_temp)\n",
    "                if verbose:\n",
    "                    print(f\"{D_temp} tiene caim de: {caim_value}\")\n",
    "                if caim_value > bc: #si el caim es mejor cambiamos bc y D\n",
    "                    if verbose:\n",
    "                        print(f\"Este caim es mejor, se actualiza best caim a {caim_value}\")\n",
    "                    bc = caim_value\n",
    "                    mejor_D = D_temp\n",
    "            if bc > gc:\n",
    "                gc = bc #si el mejor caim es el mejor reemplaza al global\n",
    "                D = mejor_D #el nuevo scheeme remplaza al anterior\n",
    "                if verbose:\n",
    "                    print(f\"se cambia el D, antes era {D}, ahora es {mejor_D}\")\n",
    "        json[column] = D\n",
    "        print(f\"La columna {column} tiene global caim de {gc}\\n\")\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12d3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data_pd(df, partitions):\n",
    "    discretized_df = df.copy()\n",
    "    \n",
    "    for column, breakpoints in partitions.items():\n",
    "        if column in df.columns:\n",
    "            # Obtener los valores mínimo y máximo para al columna \n",
    "            min_val = df[column].min()\n",
    "            max_val = df[column].max() + 0.01  # sumo el máximo para que clasifique bien los extremos\n",
    "            \n",
    "            # Asegurarse de que los puntos de partición incluyen estos valores ajustados\n",
    "            effective_breakpoints = sorted(set(breakpoints + [min_val, max_val]))\n",
    "            \n",
    "            # Usar pd.cut para asignar categorías a los valores basados en los puntos de partición\n",
    "            discretized_df[column] = pd.cut(df[column], bins=effective_breakpoints, labels=False, right=False, include_lowest=True)\n",
    "            discretized_df[column] += 1  # Ajustar índices para evitar etiquetas 0\n",
    "\n",
    "    return discretized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8ac4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def fit(self, df, label_column):\n",
    "        self.classes = df[label_column].unique()\n",
    "        self.parameters = {}\n",
    "        grouped_data = df.groupby(label_column)\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            X_cls = grouped_data.get_group(cls).drop(columns=[label_column]) #solo datos sin etiqueta\n",
    "            #diccionario para guardar la prob apriori y la verosimilitud\n",
    "            self.parameters[cls] = {\n",
    "                'prior': len(X_cls) / len(df),\n",
    "                'likelihoods': {col: self.calculate_likelihood(X_cls[col]) for col in X_cls}\n",
    "            }\n",
    "\n",
    "    def calculate_likelihood(self, feature):\n",
    "        value_counts = feature.value_counts(normalize=True)\n",
    "        return value_counts.to_dict()\n",
    "\n",
    "    def predict(self, df):\n",
    "        y_pred = []\n",
    "        for idx, row in df.iterrows():\n",
    "            posteriors = []\n",
    "            for cls in self.classes:\n",
    "                prior = self.parameters[cls]['prior']\n",
    "                likelihood = np.prod([self.parameters[cls]['likelihoods'][col].get(val, 1e-6) for col, val in row.items()])\n",
    "                posteriors.append(prior * likelihood)\n",
    "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
    "        return pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041cffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, k=3, shuffle=True):\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1).reset_index(drop=True)  # Mezclar los datos aleatoriamente\n",
    "    fold_size = len(data) // k\n",
    "    acc_scores = []\n",
    "    target = list(data.columns)[-1]  # La etiqueta siempre es la última columna\n",
    "    \n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i != k - 1 else len(data)\n",
    "        test_df = data.iloc[start:end]\n",
    "        train_df = pd.concat([data.iloc[:start], data.iloc[end:]])\n",
    "        \n",
    "        nb = NaiveBayes()\n",
    "        nb.fit(train_df, target)\n",
    "        predictions = nb.predict(test_df.drop(columns=[target]))\n",
    "        \n",
    "        # Calcula la precisión como la media de las predicciones correctas\n",
    "        # es un pd.series con true y false, el promedio es el accuracy\n",
    "        accuracy = np.mean(predictions.values == test_df[target].values)\n",
    "        \n",
    "        acc_scores.append(accuracy)\n",
    "        print(f\"Fold {i + 1}: Accuracy = {accuracy}\")\n",
    "        print(f\"Distribución etiquetas de entrenamiento:\\n{train_df[target].value_counts()}\")\n",
    "        print(f\"Distribución etiquetas de prueba:\\n{test_df[target].value_counts()}\\n\")\n",
    "    \n",
    "    return acc_scores, np.mean(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8948e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_cross_validation(data, k=3, shuffle=True):\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Preparar la estructura para guardar los folds de cada clase\n",
    "    folds = {i: pd.DataFrame() for i in range(k)}\n",
    "    target = data.columns[-1]  # Asume que la última columna es la etiqueta\n",
    "    class_proportions = data[target].value_counts(normalize=True)\n",
    "    \n",
    "    # Dividir los datos por clase y estratificar en folds\n",
    "    for cls, proportion in class_proportions.items():\n",
    "        class_data = data[data[target] == cls]\n",
    "        fold_size = len(class_data) // k\n",
    "        remain = len(class_data) % k\n",
    "        start = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            if i < remain:\n",
    "                end = start + fold_size + 1\n",
    "            else:\n",
    "                end = start + fold_size\n",
    "            \n",
    "            folds[i] = pd.concat([folds[i], class_data.iloc[start:end]])\n",
    "            start = end\n",
    "    \n",
    "    # Shuffle folds if required\n",
    "    if shuffle:\n",
    "        for i in range(k):\n",
    "            folds[i] = folds[i].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    acc_scores = []\n",
    "    \n",
    "    # Evaluación cruzada en los folds\n",
    "    for i in range(k):\n",
    "        test_df = folds[i]\n",
    "        train_df = pd.concat([folds[j] for j in range(k) if j != i]).reset_index(drop=True)\n",
    "        \n",
    "        nb = NaiveBayes()\n",
    "        nb.fit(train_df, target)\n",
    "        predictions = nb.predict(test_df.drop(columns=[target]))\n",
    "        accuracy = np.mean(predictions.values == test_df[target].values)\n",
    "        \n",
    "        acc_scores.append(accuracy)\n",
    "        print(f\"Fold {i + 1}: Accuracy = {accuracy}\")\n",
    "    \n",
    "    return acc_scores, np.mean(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2f4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"iris\" #cambiar el nombre a alguna otra base de datos\n",
    "data = pd.read_csv(csv_file + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222468d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_len  sepal_wid  petal_len  petal_wid           class\n",
       "0          5.1        3.5        1.4        0.2     Iris-setosa\n",
       "1          4.9        3.0        1.4        0.2     Iris-setosa\n",
       "2          4.7        3.2        1.3        0.2     Iris-setosa\n",
       "3          4.6        3.1        1.5        0.2     Iris-setosa\n",
       "4          5.0        3.6        1.4        0.2     Iris-setosa\n",
       "..         ...        ...        ...        ...             ...\n",
       "145        6.7        3.0        5.2        2.3  Iris-virginica\n",
       "146        6.3        2.5        5.0        1.9  Iris-virginica\n",
       "147        6.5        3.0        5.2        2.0  Iris-virginica\n",
       "148        6.2        3.4        5.4        2.3  Iris-virginica\n",
       "149        5.9        3.0        5.1        1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b761a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna sepal_len tiene global caim de 31.912646675358538\n",
      "\n",
      "La columna sepal_wid tiene global caim de 23.790685128573998\n",
      "\n",
      "La columna petal_len tiene global caim de 45.55892255892255\n",
      "\n",
      "La columna petal_wid tiene global caim de 46.16156736446592\n",
      "\n",
      "Columna \"sepal_len\" tiene partición [4.3, 5.6, 7.9]\n",
      "\n",
      "Columna \"sepal_wid\" tiene partición [2.0, 3.1, 4.4]\n",
      "\n",
      "Columna \"petal_len\" tiene partición [1.0, 3.0, 4.8, 6.9]\n",
      "\n",
      "Columna \"petal_wid\" tiene partición [0.1, 1.0, 1.8, 2.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intervals = caim(data)\n",
    "for key in intervals:\n",
    "    print(f\"Columna \\\"{key}\\\" tiene partición {intervals[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba4d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_disc = discretize_data_pd(data,intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35f4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_len  sepal_wid  petal_len  petal_wid           class\n",
       "0            1          2          1          1     Iris-setosa\n",
       "1            1          1          1          1     Iris-setosa\n",
       "2            1          2          1          1     Iris-setosa\n",
       "3            1          2          1          1     Iris-setosa\n",
       "4            1          2          1          1     Iris-setosa\n",
       "..         ...        ...        ...        ...             ...\n",
       "145          2          1          3          3  Iris-virginica\n",
       "146          2          1          3          3  Iris-virginica\n",
       "147          2          1          3          3  Iris-virginica\n",
       "148          2          2          3          3  Iris-virginica\n",
       "149          2          1          3          3  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbaed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_disc.to_csv(csv_file +'_disc.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be0f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "target = list(data_disc.columns)[-1]\n",
    "nb.fit(data, target)\n",
    "predictions = nb.predict(data.drop(columns=[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91f641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.94\n",
      "Distribución etiquetas de entrenamiento:\n",
      "Iris-virginica     34\n",
      "Iris-versicolor    33\n",
      "Iris-setosa        33\n",
      "Name: class, dtype: int64\n",
      "Distribución etiquetas de prueba:\n",
      "Iris-setosa        17\n",
      "Iris-versicolor    17\n",
      "Iris-virginica     16\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Fold 2: Accuracy = 0.96\n",
      "Distribución etiquetas de entrenamiento:\n",
      "Iris-versicolor    35\n",
      "Iris-setosa        34\n",
      "Iris-virginica     31\n",
      "Name: class, dtype: int64\n",
      "Distribución etiquetas de prueba:\n",
      "Iris-virginica     19\n",
      "Iris-setosa        16\n",
      "Iris-versicolor    15\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Fold 3: Accuracy = 0.88\n",
      "Distribución etiquetas de entrenamiento:\n",
      "Iris-virginica     35\n",
      "Iris-setosa        33\n",
      "Iris-versicolor    32\n",
      "Name: class, dtype: int64\n",
      "Distribución etiquetas de prueba:\n",
      "Iris-versicolor    18\n",
      "Iris-setosa        17\n",
      "Iris-virginica     15\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Precisión en cada fold: [0.94, 0.96, 0.88]\n",
      "Precisión media: 0.9266666666666666\n"
     ]
    }
   ],
   "source": [
    "scores, mean_accuracy = k_fold_cross_validation(data_disc, k=3)\n",
    "print(\"Precisión en cada fold:\", scores)\n",
    "print(\"Precisión media:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b463b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9803921568627451\n",
      "Fold 2: Accuracy = 0.9215686274509803\n",
      "Fold 3: Accuracy = 0.9375\n",
      "Presición media: 0.9464869281045751\n"
     ]
    }
   ],
   "source": [
    "s_scores = stratified_k_fold_cross_validation(data_disc, k=3, shuffle=True)\n",
    "print(f\"Presición media: {s_scores[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
